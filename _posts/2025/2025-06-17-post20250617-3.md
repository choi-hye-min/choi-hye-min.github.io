---
layout: post
title: "Spring Boot 3 + Kotlin으로 Kafka Producer 실무 구현 완벽 가이드"
date: 2025-06-16 22:00:00 +0900
categories: [Kafka, SpringBoot3, Kotlin, 백엔드, 실전]
tags: [kafka, springboot3, kotlin, producer, 메시지큐, 백엔드, 실전, 초보자]
---

> 이 글은 Spring Boot 3와 Kotlin을 활용해 실무에서 확장성과 신뢰성을 갖춘 Kafka Producer를 구현하는 방법을 초보자도 쉽게 따라할 수 있도록 단계별로 안내합니다. 환경 준비, 설정, 코드 예제, 장애/성능/운영 팁, 자주 묻는 질문, 참고자료까지 실전 중심으로 모두 담았습니다.

---

#### Kafka Producer란 무엇인가?

- Producer는 Kafka 토픽에 메시지를 발행하는 역할을 합니다.
- 실시간 로그, 이벤트, 트랜잭션 데이터 등 다양한 메시지를 다양한 서비스에 전달할 때 필수적입니다.
- Producer의 안정성과 확장성, 메시지 전송 보장(ack, retry, idempotence)이 실무에서 매우 중요합니다.

#### Spring Boot 3 + Kotlin 환경에서 Kafka Producer를 써야 하는 이유

- Spring Boot 3는 최신 Kafka 클라이언트와의 호환성, 간편한 설정, 강력한 의존성 관리 제공
- Kotlin은 간결한 문법, 널 안정성, 함수형 프로그래밍 지원으로 생산성 향상
- 실무에서 Producer 구현의 복잡성을 크게 낮추고, 운영/모니터링/보안까지 통합 가능

---

#### 실전 환경 준비

- **필수 조건**: JDK 17+, Spring Boot 3.x, Kafka 브로커(로컬/클라우드), Gradle/Maven
- **주요 라이브러리**: `spring-kafka`, `kotlin`, `spring-boot-starter`

##### Gradle 의존성 예시

```kotlin
dependencies {
    implementation("org.springframework.boot:spring-boot-starter")
    implementation("org.springframework.kafka:spring-kafka")
    implementation("org.jetbrains.kotlin:kotlin-reflect")
    implementation("org.jetbrains.kotlin:kotlin-stdlib-jdk8")
    testImplementation("org.springframework.boot:spring-boot-starter-test")
    testImplementation("org.springframework.kafka:spring-kafka-test")
}
```

---

#### application.yml과 Producer 설정 원리

Kafka 메시지 발행의 신뢰성과 성능을 좌우하는 핵심 설정을 이해하는 것이 중요합니다.

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
      retries: 3
      batch-size: 16384
      linger-ms: 1
      buffer-memory: 33554432
      enable-idempotence: true
```

- **주요 옵션 설명**
  | 옵션명 | 설명 | 실전 팁 |
  |---|---|---|
  | bootstrap-servers | Kafka 브로커 주소 | 장애 대비 다중 입력 권장 |
  | key/value-serializer | 메시지 직렬화 방식 | JSON, Avro 등 데이터 포맷에 맞게 변경 |
  | acks | 메시지 전송 보장 수준 | all(최고 신뢰), 1, 0 선택 가능 |
  | retries | 전송 실패 시 재시도 횟수 | 네트워크 장애 대비 필수 |
  | batch-size | 배치 전송 크기 | TPS/지연 요구에 따라 조정 |
  | linger-ms | 배치 대기 시간 | 0~수 ms, 지연/성능 트레이드오프 |
  | enable-idempotence | 중복 전송 방지 | 실무 필수 옵션 |

---

#### Kafka Producer 실전 구현 (Kotlin)

##### 1. 기본 Producer Service (동기/비동기)

```kotlin
@Service
class MyKafkaProducer(
    private val kafkaTemplate: KafkaTemplate<String, String>
) {
    // 비동기 전송 (실무 기본)
    fun sendAsync(topic: String, message: String) {
        kafkaTemplate.send(topic, message)
        println("[Kafka] 비동기 발행: $topic -> $message")
    }

    // 동기 전송 (결과 보장 필요 시)
    fun sendSync(topic: String, message: String) {
        val result = kafkaTemplate.send(topic, message).get() // blocking
        println("[Kafka] 동기 발행: $topic, partition=${result.recordMetadata.partition()}, offset=${result.recordMetadata.offset()}")
    }
}
```

##### 2. JSON/커스텀 객체 메시지 전송

```kotlin
data class OrderEvent(val orderId: Long, val status: String)

@Service
class JsonKafkaProducer(
    private val kafkaTemplate: KafkaTemplate<String, OrderEvent>
) {
    fun sendOrder(topic: String, event: OrderEvent) {
        kafkaTemplate.send(topic, event)
        println("[Kafka] 주문 이벤트 발행: $event")
    }
}
```

##### 3. 콜백/에러 처리 예시

```kotlin
fun sendWithCallback(topic: String, message: String) {
    kafkaTemplate.send(topic, message).addCallback(
        { result -> println("[Kafka] 성공: ${result?.recordMetadata}") },
        { ex -> println("[Kafka] 실패: ${ex.message}") }
    )
}
```

##### 4. Kafka 트랜잭션 Producer 예시

```kotlin
@Service
class TransactionalProducer(
    private val kafkaTemplate: KafkaTemplate<String, String>
) {
    @Transactional
    fun sendInTransaction(topic: String, message: String) {
        kafkaTemplate.executeInTransaction {
            it.send(topic, message)
            // DB 등 다른 트랜잭션 연동 가능
        }
    }
}
```

##### 5. 배치 전송 예시

```kotlin
fun sendBatch(topic: String, messages: List<String>) {
    messages.forEach { kafkaTemplate.send(topic, it) }
    println("[Kafka] 배치 발행: ${messages.size}건")
}
```

##### 6. 실전 Controller/테스트 코드 예시

```kotlin
@RestController
@RequestMapping("/kafka")
class KafkaProducerController(
    private val producer: MyKafkaProducer,
    private val jsonProducer: JsonKafkaProducer
) {
    @PostMapping("/send")
    fun send(@RequestParam topic: String, @RequestBody message: String) =
        producer.sendAsync(topic, message)

    @PostMapping("/sendSync")
    fun sendSync(@RequestParam topic: String, @RequestBody message: String) =
        producer.sendSync(topic, message)

    @PostMapping("/sendOrder")
    fun sendOrder(@RequestParam topic: String, @RequestBody event: OrderEvent) =
        jsonProducer.sendOrder(topic, event)
}
```

##### 7. Kafka Producer 테스트 코드 (EmbeddedKafka)

```kotlin
@SpringBootTest
@EmbeddedKafka(partitions = 1, topics = ["test-topic"])
class KafkaProducerTest {
    @Autowired lateinit var kafkaTemplate: KafkaTemplate<String, String>

    @Test
    fun testSend() {
        kafkaTemplate.send("test-topic", "hello").get()
        // Consumer로 메시지 수신 검증 코드 추가 가능
    }
}
```

---

##### 실전 대화/FAQ/실수 사례

- **Q. 동기/비동기 전송 언제 써야 하나요?**
  - A. 실시간 처리/성능 우선이면 비동기, 주문/결제 등 결과 보장 필요시 동기 사용
- **Q. JSON/커스텀 객체 전송 시 직렬화는?**
  - A. application.yml에서 value-serializer를 JsonSerializer로 지정, DTO에 @JsonProperty 등 추가
- **Q. 콜백/에러 핸들링 실수**
  - A. 콜백 미구현 시 장애/유실 발생 가능, 반드시 성공/실패 로깅 및 알림 처리
- **Q. 트랜잭션 Producer 실수**
  - A. enable-idempotence=true, transactional-id 지정 필수, DB 트랜잭션 연동 시 주의
- **Q. 배치 전송 시 주의점**
  - A. TPS/지연 요구에 따라 batch-size/linger-ms 튜닝, 메시지 순서/중복 관리

---

---

#### 실무 장애/성능/운영 사례와 해결 전략

| 사고 유형 | 원인 | 결과 | 해결책 |
|---|---|---|---|
| 메시지 유실 | acks=0, 네트워크 장애 | 일부 데이터 손실 | acks=all, retries, 에러 핸들링 |
| 중복 전송 | idempotence 미설정, 재시도 | 데이터 중복 | enable-idempotence, 메시지 키 관리 |
| TPS 저하 | batch-size/linger-ms 미조정 | 지연 증가 | 배치/버퍼/스레드 튜닝 |
| 운영 장애 | 토픽/파티션/브로커 설정 오류 | 서비스 중단 | 설정 문서화, 모니터링, 자동화 |

---

#### Producer 운영 자동화/모니터링/보안

- **운영 자동화**: 배포 스크립트, 토픽/파티션 관리 자동화, CI/CD 연동
- **모니터링**: TPS, 에러율, 지연, 전송 실패 등 Grafana, Prometheus, JMX Exporter 활용
- **보안**: SASL 인증, TLS 암호화, ACL 권한 관리, 민감 정보 마스킹
- **장애 대응**: 알림 시스템, 자동 재시작, 장애 메시지 추적 대시보드 구축

##### 실전 운영 체크리스트

- [ ] TPS/에러율/지연 실시간 모니터링
- [ ] 장애 발생 시 알림/자동 재시작 체계 구축
- [ ] 토픽/파티션/설정 문서화
- [ ] 운영/배포 자동화 스크립트화
- [ ] 보안 설정(SASL, TLS, ACL) 적용

---

#### 실전 Q&A, 오해와 진실

- `acks=all이면 절대 유실이 없다?` → **오해!**: 브로커 장애, 네트워크 이슈 등으로 유실 가능
- `idempotence는 꼭 켜야 하나?` → **실무 필수!**: 재시도 시 중복 방지, 데이터 신뢰성 보장
- `배치 전송이 항상 빠르다?` → **부분 오해!**: TPS/지연 요구에 따라 batch-size/linger-ms 튜닝 필요
- `Spring Boot만 쓰면 안전하다?` → **오해!**: 설정/예외처리/운영 전략 직접 챙겨야 함

---

#### 실전 대화 예시: 장애 상황과 협업

| 상황 | 대화 | 결과 |
|---|---|---|
| 메시지 유실 | "왜 일부 이벤트가 누락됐죠?"<br>"acks=0 설정과 네트워크 장애로 유실됐습니다." | acks=all, 에러 핸들링 강화 |
| 중복 전송 | "이벤트가 두 번씩 처리돼요."<br>"idempotence 옵션을 반드시 켜고, 메시지 키 설계도 신경써야 합니다." | 중복 방지 체계 강화 |
| 운영 자동화 | "토픽 관리가 수동이라 실수 위험이 큽니다."<br>"운영 스크립트와 CI/CD로 자동화합시다." | 운영 효율/안정성 향상 |

---

#### Kafka Producer 실무 협업/코드 리뷰 체크리스트

- [ ] 프로듀서/토픽/파티션 구조 설계가 명확히 문서화되어 있는가?
- [ ] 예외/장애 처리(ack, retry, idempotence 등) 로직이 구현되어 있는가?
- [ ] 메시지 중복/유실/순서 보장 등 품질 이슈가 관리되고 있는가?
- [ ] 운영/배포/설정 자동화가 적용되어 있는가?
- [ ] 보안 설정 및 민감 정보 관리가 철저히 이루어지는가?
- [ ] 테스트 코드로 실제 메시지 송수신이 검증되는가?
- [ ] 모니터링/알림/대시보드가 구축되어 있는가?
- [ ] 코드 리뷰/PR 체크리스트에 위 항목이 포함되어 있는가?

---

#### Kafka Producer 실전 팁/FAQ (초보자 관점)

- **Q. 메시지 유실/중복 방지하려면?**
  - A. acks=all, enable-idempotence, 키 관리, 에러 핸들링, 재시도 정책 활용
- **Q. TPS/성능을 높이려면?**
  - A. batch-size, linger-ms, 버퍼, 스레드 등 튜닝
- **Q. 운영/테스트 환경 분리 방법은?**
  - A. 별도 Kafka 클러스터/토픽, 환경별 설정 분리, Spring Profile 활용
- **Q. Producer 보안은 어떻게 하나요?**
  - A. SASL 인증, TLS 암호화, ACL 권한 관리, 민감 정보 마스킹
- **Q. 실무에서 가장 많이 하는 실수는?**
  - A. acks=0, idempotence 미설정, 에러 미처리, 모니터링/문서화 부족

---

#### Kafka Producer 실전 배포/운영 자동화 전략

- CI/CD 파이프라인에 Kafka 관련 테스트/배포 자동화 포함
- 운영 스크립트로 토픽/파티션 관리 자동화
- 장애 발생 시 자동 재시작/알림 시스템 연동
- 모니터링 대시보드(Grafana, Prometheus) 구축
- 문서화/운영 정책/장애 이력 체계적 관리

---

#### Kafka Producer 실전 보안/품질 관리

- SASL, TLS, ACL 등 보안 정책 적용
- 민감 정보(토큰, 개인정보 등) 마스킹/암호화
- 메시지 유효성 검증, 중복/순서/유실 방지 로직 적용
- 운영/배포/테스트 환경 분리 및 접근 제어

---

#### 결론 및 도움말

> Kafka Producer 실무에서는 메시지 신뢰성, 중복/유실 방지, 자동화/모니터링/보안까지 모두 신경써야 합니다. 초보자도 실전 사례, 체크리스트, 자동화/모니터링 도구를 적극 활용하면 안정적이고 효율적인 메시지 발행이 가능합니다. 공식 문서와 다양한 실전 사례, 오픈소스 도구를 참고해 꾸준히 경험을 쌓아보세요.

---

#### 참고자료/레퍼런스

- [Spring for Apache Kafka 공식 문서](https://docs.spring.io/spring-kafka/docs/current/reference/html/)
- [Kotlin + Spring Boot Kafka 실전 예제](https://github.com/spring-projects/spring-kafka/tree/main/samples)
- [Kafka 공식 문서](https://kafka.apache.org/documentation/)
- [Kafka Streams와 실시간 처리](https://kafka.apache.org/documentation/streams/)
- [실전 Kafka 운영 노하우](https://engineering.linecorp.com/ko/blog/kafka-in-production/)
- [Kafka 보안 가이드](https://docs.confluent.io/platform/current/security/index.html)
- [Kafka Monitoring with Prometheus](https://prometheus.io/docs/guides/kafka/)
- [Kafka Producer 신뢰성 가이드](https://www.confluent.io/blog/transactions-ensure-exactly-once-kafka/)
- [Kafka Producer 배치/성능 공식 가이드](https://kafka.apache.org/documentation/#producerconfigs)
